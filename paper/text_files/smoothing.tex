% tex file for smoothing
\par \indent Due to the inherently random nature of human subjects and their movements, a certain level of smoothing must be performed on the spatial dataset. That way, the ‘noisy’ data can be cast off from the data that actually represents significant changes in blood flow in the brain. By doing so, researchers and anyone else investigating the data will be able to distinguish between non-brain scans versus actual brain scans. Each voxel of the brain is represented by a measure of blood flow intensity, and so a series of steps must be taken so that the data is correctly convolved to most closely and accurately depict what was happening at a certain point in the brain at a certain time. After researching quite extensively, we decided to use convolution involving a Gaussian kernel in order to smooth the three dimensional data. Originally, we were going to try and write a smoothing function from scratch, by implementing a rudimentary average-over-neighbors method. However, discussion with mentors lead us to the scipy module \texttt{ndimage.filters} that has a function to performs a Gaussian filter on n-dimensional data. This was exactly what we needed so rather than reinventing the wheel, we will be smoothing the data with this module.
